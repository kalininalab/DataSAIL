{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split PDBBind in Two Dimensions\n",
    "\n",
    "In this example notebook, we will discuss how to use DataSAIL to compute split for the PDBBind core-dataset to compute more challenging splits for machine learning models. Here, we will demonstrate how to preprocess and split a more complex dataset. Therefore, we first import all necessary tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import deepchem as dc\n",
    "from rdkit import Chem\n",
    "\n",
    "from datasail.sail import datasail"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the Dataset\n",
    "\n",
    "Load the dataset from deepchem. As usual, we remove the weights.\n",
    "\n",
    "When looking at the resulting \"Target\" column of the dataframe, one can see that the interaction dataset focuses on predicting ligand-pocket binding affnities. This makes sense as a model can focus on specifics of the pocket instead of dealing with the entire protein which may be uninteresting. Therefore, it makes sense to apply DataSAIL to the pockets as well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      ids                                Ligand  \\\n0    2d3u  /tmp/v2013-core/2d3u/2d3u_ligand.sdf   \n1    3cyx  /tmp/v2013-core/3cyx/3cyx_ligand.sdf   \n2    3uo4  /tmp/v2013-core/3uo4/3uo4_ligand.sdf   \n3    1p1q  /tmp/v2013-core/1p1q/1p1q_ligand.sdf   \n4    3ag9  /tmp/v2013-core/3ag9/3ag9_ligand.sdf   \n..    ...                                   ...   \n188  2x0y  /tmp/v2013-core/2x0y/2x0y_ligand.sdf   \n189  3uex  /tmp/v2013-core/3uex/3uex_ligand.sdf   \n190  2pq9  /tmp/v2013-core/2pq9/2pq9_ligand.sdf   \n191  1u1b  /tmp/v2013-core/1u1b/1u1b_ligand.sdf   \n192  4gqq  /tmp/v2013-core/4gqq/4gqq_ligand.sdf   \n\n                                   Target         y  \n0    /tmp/v2013-core/2d3u/2d3u_pocket.pdb  0.268375  \n1    /tmp/v2013-core/3cyx/3cyx_pocket.pdb  0.749538  \n2    /tmp/v2013-core/3uo4/3uo4_pocket.pdb  0.090166  \n3    /tmp/v2013-core/1p1q/1p1q_pocket.pdb -0.636034  \n4    /tmp/v2013-core/3ag9/3ag9_pocket.pdb  0.771814  \n..                                    ...       ...  \n188  /tmp/v2013-core/2x0y/2x0y_pocket.pdb -0.765235  \n189  /tmp/v2013-core/3uex/3uex_pocket.pdb  0.268375  \n190  /tmp/v2013-core/2pq9/2pq9_pocket.pdb  0.798545  \n191  /tmp/v2013-core/1u1b/1u1b_pocket.pdb  0.660433  \n192  /tmp/v2013-core/4gqq/4gqq_pocket.pdb -1.527076  \n\n[193 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ids</th>\n      <th>Ligand</th>\n      <th>Target</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2d3u</td>\n      <td>/tmp/v2013-core/2d3u/2d3u_ligand.sdf</td>\n      <td>/tmp/v2013-core/2d3u/2d3u_pocket.pdb</td>\n      <td>0.268375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3cyx</td>\n      <td>/tmp/v2013-core/3cyx/3cyx_ligand.sdf</td>\n      <td>/tmp/v2013-core/3cyx/3cyx_pocket.pdb</td>\n      <td>0.749538</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3uo4</td>\n      <td>/tmp/v2013-core/3uo4/3uo4_ligand.sdf</td>\n      <td>/tmp/v2013-core/3uo4/3uo4_pocket.pdb</td>\n      <td>0.090166</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1p1q</td>\n      <td>/tmp/v2013-core/1p1q/1p1q_ligand.sdf</td>\n      <td>/tmp/v2013-core/1p1q/1p1q_pocket.pdb</td>\n      <td>-0.636034</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3ag9</td>\n      <td>/tmp/v2013-core/3ag9/3ag9_ligand.sdf</td>\n      <td>/tmp/v2013-core/3ag9/3ag9_pocket.pdb</td>\n      <td>0.771814</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>2x0y</td>\n      <td>/tmp/v2013-core/2x0y/2x0y_ligand.sdf</td>\n      <td>/tmp/v2013-core/2x0y/2x0y_pocket.pdb</td>\n      <td>-0.765235</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>3uex</td>\n      <td>/tmp/v2013-core/3uex/3uex_ligand.sdf</td>\n      <td>/tmp/v2013-core/3uex/3uex_pocket.pdb</td>\n      <td>0.268375</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>2pq9</td>\n      <td>/tmp/v2013-core/2pq9/2pq9_ligand.sdf</td>\n      <td>/tmp/v2013-core/2pq9/2pq9_pocket.pdb</td>\n      <td>0.798545</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>1u1b</td>\n      <td>/tmp/v2013-core/1u1b/1u1b_ligand.sdf</td>\n      <td>/tmp/v2013-core/1u1b/1u1b_pocket.pdb</td>\n      <td>0.660433</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>4gqq</td>\n      <td>/tmp/v2013-core/4gqq/4gqq_ligand.sdf</td>\n      <td>/tmp/v2013-core/4gqq/4gqq_pocket.pdb</td>\n      <td>-1.527076</td>\n    </tr>\n  </tbody>\n</table>\n<p>193 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dc.molnet.load_pdbbind(featurizer=dc.feat.DummyFeaturizer(), splitter=None, set_name=\"core\")\n",
    "df = dataset[1][0].to_dataframe()\n",
    "df.rename(columns={\"X1\": \"Ligand\", \"X2\": \"Target\"}, inplace=True)\n",
    "df = df[[\"ids\", \"Ligand\", \"Target\", \"y\"]]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparation of Ligands\n",
    "\n",
    "This time, the ligands are given in SDF files which need to be converted to SMILES strings. For this, we first write a simple converter function, apply this to all ligands, and remove eventually created NaN values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:05:12] Explicit valence for atom # 50 C greater than permitted\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 287\n",
      "[10:05:12] ERROR: Explicit valence for atom # 50 C greater than permitted\n",
      "[10:05:12] Explicit valence for atom # 0 C greater than permitted\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 48\n",
      "[10:05:12] ERROR: Explicit valence for atom # 0 C greater than permitted\n",
      "[10:05:12] Explicit valence for atom # 26 C greater than permitted\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 119\n",
      "[10:05:12] ERROR: Explicit valence for atom # 26 C greater than permitted\n",
      "[10:05:12] Explicit valence for atom # 26 C greater than permitted\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 116\n",
      "[10:05:12] ERROR: Explicit valence for atom # 26 C greater than permitted\n",
      "[10:05:12] Explicit valence for atom # 4 C greater than permitted\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 108\n",
      "[10:05:12] ERROR: Explicit valence for atom # 4 C greater than permitted\n",
      "[10:05:12] Explicit valence for atom # 23 C greater than permitted\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 146\n",
      "[10:05:12] ERROR: Explicit valence for atom # 23 C greater than permitted\n",
      "[10:05:12] Explicit valence for atom # 2 C greater than permitted\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 45\n",
      "[10:05:12] ERROR: Explicit valence for atom # 2 C greater than permitted\n",
      "[10:05:12] Explicit valence for atom # 42 C greater than permitted\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 172\n",
      "[10:05:12] ERROR: Explicit valence for atom # 42 C greater than permitted\n",
      "[10:05:12] Explicit valence for atom # 6 C greater than permitted\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 94\n",
      "[10:05:12] ERROR: Explicit valence for atom # 6 C greater than permitted\n",
      "[10:05:12] Explicit valence for atom # 28 C greater than permitted\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 159\n",
      "[10:05:12] ERROR: Explicit valence for atom # 28 C greater than permitted\n",
      "[10:05:12] Can't kekulize mol.  Unkekulized atoms: 2 6 7 17 23 24 25\n",
      "[10:05:12] ERROR: Could not sanitize molecule ending on line 114\n",
      "[10:05:12] ERROR: Can't kekulize mol.  Unkekulized atoms: 2 6 7 17 23 24 25\n"
     ]
    },
    {
     "data": {
      "text/plain": "      ids                                             Ligand  \\\n0    2d3u  Cc1ccccc1S(=O)(=O)Nc1cc(-c2ccc(C#N)cc2)sc1C(=O...   \n1    3cyx  CC(C)(C)NC(=O)[C@@H]1C[C@@H]2CCCC[C@@H]2C[N@H+...   \n2    3uo4   O=C([O-])c1ccc(Nc2nccc(Nc3ccccc3-c3ccccc3)n2)cc1   \n3    1p1q             Cc1o[nH]c(=O)c1C[C@H]([NH3+])C(=O)[O-]   \n5    2wtv  O=C([O-])c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(...   \n..    ...                                                ...   \n188  2x0y               Cn1c(=O)c2c(ncn2C[C@H](O)CO)n(C)c1=O   \n189  3uex                         CCCCCCCCCCCCCCCCCC(=O)[O-]   \n190  2pq9  O=C([O-])C1=C[C@@H](OP(=O)([O-])[O-])[C@@H](O)...   \n191  1u1b  Cc1cn([C@H]2C[C@H](O[P@](=O)([O-])O[P@](=O)([O...   \n192  4gqq                        CCOC(=O)/C=C/c1ccc(O)c(O)c1   \n\n                                   Target         y  \n0    /tmp/v2013-core/2d3u/2d3u_pocket.pdb  0.268375  \n1    /tmp/v2013-core/3cyx/3cyx_pocket.pdb  0.749538  \n2    /tmp/v2013-core/3uo4/3uo4_pocket.pdb  0.090166  \n3    /tmp/v2013-core/1p1q/1p1q_pocket.pdb -0.636034  \n5    /tmp/v2013-core/2wtv/2wtv_pocket.pdb  1.079223  \n..                                    ...       ...  \n188  /tmp/v2013-core/2x0y/2x0y_pocket.pdb -0.765235  \n189  /tmp/v2013-core/3uex/3uex_pocket.pdb  0.268375  \n190  /tmp/v2013-core/2pq9/2pq9_pocket.pdb  0.798545  \n191  /tmp/v2013-core/1u1b/1u1b_pocket.pdb  0.660433  \n192  /tmp/v2013-core/4gqq/4gqq_pocket.pdb -1.527076  \n\n[182 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ids</th>\n      <th>Ligand</th>\n      <th>Target</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2d3u</td>\n      <td>Cc1ccccc1S(=O)(=O)Nc1cc(-c2ccc(C#N)cc2)sc1C(=O...</td>\n      <td>/tmp/v2013-core/2d3u/2d3u_pocket.pdb</td>\n      <td>0.268375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3cyx</td>\n      <td>CC(C)(C)NC(=O)[C@@H]1C[C@@H]2CCCC[C@@H]2C[N@H+...</td>\n      <td>/tmp/v2013-core/3cyx/3cyx_pocket.pdb</td>\n      <td>0.749538</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3uo4</td>\n      <td>O=C([O-])c1ccc(Nc2nccc(Nc3ccccc3-c3ccccc3)n2)cc1</td>\n      <td>/tmp/v2013-core/3uo4/3uo4_pocket.pdb</td>\n      <td>0.090166</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1p1q</td>\n      <td>Cc1o[nH]c(=O)c1C[C@H]([NH3+])C(=O)[O-]</td>\n      <td>/tmp/v2013-core/1p1q/1p1q_pocket.pdb</td>\n      <td>-0.636034</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2wtv</td>\n      <td>O=C([O-])c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(...</td>\n      <td>/tmp/v2013-core/2wtv/2wtv_pocket.pdb</td>\n      <td>1.079223</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>2x0y</td>\n      <td>Cn1c(=O)c2c(ncn2C[C@H](O)CO)n(C)c1=O</td>\n      <td>/tmp/v2013-core/2x0y/2x0y_pocket.pdb</td>\n      <td>-0.765235</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>3uex</td>\n      <td>CCCCCCCCCCCCCCCCCC(=O)[O-]</td>\n      <td>/tmp/v2013-core/3uex/3uex_pocket.pdb</td>\n      <td>0.268375</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>2pq9</td>\n      <td>O=C([O-])C1=C[C@@H](OP(=O)([O-])[O-])[C@@H](O)...</td>\n      <td>/tmp/v2013-core/2pq9/2pq9_pocket.pdb</td>\n      <td>0.798545</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>1u1b</td>\n      <td>Cc1cn([C@H]2C[C@H](O[P@](=O)([O-])O[P@](=O)([O...</td>\n      <td>/tmp/v2013-core/1u1b/1u1b_pocket.pdb</td>\n      <td>0.660433</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>4gqq</td>\n      <td>CCOC(=O)/C=C/c1ccc(O)c(O)c1</td>\n      <td>/tmp/v2013-core/4gqq/4gqq_pocket.pdb</td>\n      <td>-1.527076</td>\n    </tr>\n  </tbody>\n</table>\n<p>182 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sdf2smiles(x):\n",
    "    mols = Chem.SDMolSupplier(x)\n",
    "    if len(mols) != 1:\n",
    "        # drop ambiguous molecules. If the target binds to none or multiple ligands, the binding affinity might be ambiguous\n",
    "        return None\n",
    "    for mol in mols:\n",
    "        if mol is None:\n",
    "            # if the read molecule is invalid, this cannot be converted as well\n",
    "            return None\n",
    "        return Chem.MolToSmiles(mol)\n",
    "\n",
    "\n",
    "df[\"Ligand\"] = df[\"Ligand\"].apply(sdf2smiles)\n",
    "df.dropna(inplace=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparation of Targets\n",
    "\n",
    "Here, we just copy all pdb files into one folder. This is a requirement of FoldSeek, the internally used algorithm to cluster PDB data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "os.makedirs(\"pdbs\", exist_ok=True)\n",
    "for name, filename in df[[\"ids\", \"Target\"]].values.tolist():\n",
    "    shutil.copyfile(filename, f\"pdbs/{name}.pdb\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run DataSAIL\n",
    "\n",
    "Use DataSAIL to split pdbbind with every technique offered. We define\n",
    "  - the techniques as list: R, I1e, I1f, I2, C1e, C1f, and C1\n",
    "    The e in the end is important to split the e-data, the f for f-data accordingly.\n",
    "  - the spits as list. The values will be normalized to ratios.\n",
    "  - the names as list. Similarly to the list of split sizes, DataSAIL needs names to name the splits.\n",
    "  - the number of runs. This will determine how many different splits to compute per technique to compute.\n",
    "  - the solving algorithm for optimizing the final problem formulation.\n",
    "  - the type of the dataset in the first axis (ligands).\n",
    "  - the data as mapping from IDs to SMILES strings (ligands).\n",
    "  - the type of the dataset in the second axis (targets).\n",
    "  - the location of the PDB folder.\n",
    "  \n",
    "For an extensive description of the arguments please refer to the according pages of the documentation.\n",
    "\n",
    "Given there exist files storing the data as described in the documentation, the according call to DataSAIL in the commandline would be:\n",
    "```bash\n",
    "$ datasail -t R I1e I2f I2 C1e C1f C2 -s 7 2 1 -n train val test -r 3 -i inter.tsv --solver SCIP --e-type M --e-data <filepath> --f-type P --f-data <pdb_dir>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "%%capture\n",
    "e_splits, f_splits, inter_splits = datasail(\n",
    "    techniques=[\"R\", \"I1e\", \"I1f\", \"I2\", \"C1e\", \"C1f\", \"C2\"],\n",
    "    splits=[7, 2, 1],\n",
    "    names=[\"train\", \"val\", \"test\"],\n",
    "    runs=3,\n",
    "    solver=\"SCIP\",\n",
    "    inter=[(x[0], x[0]) for x in df[[\"ids\"]].values.tolist()],\n",
    "    e_type=\"M\",\n",
    "    e_data=dict(df[[\"ids\", \"Ligand\"]].values.tolist()),\n",
    "    f_type=\"P\",\n",
    "    f_data=\"pdbs\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The output\n",
    "\n",
    "Finally, we inspect the returned split assignments as this holds all the assignments of the datapoints to the splits, for each run and each technique. First, the overall architecture is described, lastly we look at the first five assignments of the C1 run 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "I1e - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "I2 - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "C1e - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "C2 - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "\n",
      "ID: 2d3u - Split: val\n",
      "ID: 3cyx - Split: val\n",
      "ID: 3pww - Split: val\n",
      "ID: 3uo4 - Split: train\n",
      "ID: 1p1q - Split: train\n"
     ]
    }
   ],
   "source": [
    "print(type(e_splits))\n",
    "for key in e_splits.keys():\n",
    "    print(f\"{key} - Type: {type(e_splits[key])} - Length: {len(e_splits[key])}\")\n",
    "    for run in range(len(e_splits[key])):\n",
    "        print(f\"\\tRun {run + 1} - Type: {type(e_splits[key][run])} - {len(e_splits[key][run])} assignments\")\n",
    "print(\"\\n\" + \"\\n\".join(f\"ID: {idx} - Split: {split}\" for idx, split in list(e_splits[key][0].items())[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "I1f - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "I2 - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "C1f - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "C2 - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "\n",
      "ID: 2d3u - Split: train\n",
      "ID: 3cyx - Split: val\n",
      "ID: 3uo4 - Split: train\n",
      "ID: 1p1q - Split: train\n",
      "ID: 2wtv - Split: train\n"
     ]
    }
   ],
   "source": [
    "print(type(f_splits))\n",
    "for key in f_splits.keys():\n",
    "    print(f\"{key} - Type: {type(f_splits[key])} - Length: {len(f_splits[key])}\")\n",
    "    for run in range(len(f_splits[key])):\n",
    "        print(f\"\\tRun {run + 1} - Type: {type(f_splits[key][run])} - {len(f_splits[key][run])} assignments\")\n",
    "print(\"\\n\" + \"\\n\".join(f\"ID: {idx} - Split: {split}\" for idx, split in list(f_splits[key][0].items())[:5]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "R - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "I1e - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "I1f - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "I2 - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "C1e - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "C1f - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "C2 - Type: <class 'list'> - Length: 3\n",
      "\tRun 1 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 2 - Type: <class 'dict'> - 182 assignments\n",
      "\tRun 3 - Type: <class 'dict'> - 182 assignments\n",
      "\n",
      "ID: ('2d3u', '2d3u') - Split: not selected\n",
      "ID: ('3cyx', '3cyx') - Split: val\n",
      "ID: ('3uo4', '3uo4') - Split: train\n",
      "ID: ('1p1q', '1p1q') - Split: train\n",
      "ID: ('2wtv', '2wtv') - Split: train\n"
     ]
    }
   ],
   "source": [
    "print(type(inter_splits))\n",
    "for key in inter_splits.keys():\n",
    "    print(f\"{key} - Type: {type(inter_splits[key])} - Length: {len(inter_splits[key])}\")\n",
    "    for run in range(len(inter_splits[key])):\n",
    "        print(f\"\\tRun {run + 1} - Type: {type(inter_splits[key][run])} - {len(inter_splits[key][run])} assignments\")\n",
    "print(\"\\n\" + \"\\n\".join(f\"ID: {idx} - Split: {split}\" for idx, split in list(inter_splits[key][0].items())[:5]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
