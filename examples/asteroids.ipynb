{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Split NASA Asteroids with DataSAIL\n",
    "\n",
    "In this notebook, we will investigate the transferability of DataSAIL to non-biomedical datasets. This notebook will be very similar to the notebook where we show how to split the BACE dataset by weights. Here, we will use the NASA Asteroids dataset, which contains information about asteroids and whether they are hazardous or not. We will use DataSAIL to split the dataset into training and testing sets and compare the performance of a Random Forest classifier on the two splits.\n",
    "\n",
    "As always, we first import the necessary libraries. The dataset is a CSV file in the same folder which can be downloaded from kaggle: https://www.kaggle.com/datasets/lovishbansal123/nasa-asteroids-classification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dec57347966fa48"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/miniconda3/envs/sail38/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasail.sail import datasail\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:04:34.152698600Z",
     "start_time": "2024-04-03T15:04:25.461049300Z"
    }
   },
   "id": "f1edda2f-b087-4fbe-b262-b55e25cb371d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the NASA Asteroids dataset\n",
    "\n",
    "Next, we load the dataset and clean it as usually. The dataset contains the many columns, but for demonstration purposes, we will focus on the two main diameters and the missing distance to earth in lunar metric. We will also rename the columns to make them easier to work with."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc5f67a7b8679bb3"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fda5f7-08a5-4fd3-b726-c74418f0faf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T15:04:34.440319700Z",
     "start_time": "2024-04-03T15:04:34.154777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4687, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "      dia_min     dia_max        dist  Hazardous\n0  127.219879  284.472297  163.178711       True\n1  146.067964  326.617897  148.992630      False\n2  231.502122  517.654482   19.821890       True\n3    8.801465   19.680675  110.990387      False\n4  127.219879  284.472297  158.646713       True",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dia_min</th>\n      <th>dia_max</th>\n      <th>dist</th>\n      <th>Hazardous</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>127.219879</td>\n      <td>284.472297</td>\n      <td>163.178711</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>146.067964</td>\n      <td>326.617897</td>\n      <td>148.992630</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>231.502122</td>\n      <td>517.654482</td>\n      <td>19.821890</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.801465</td>\n      <td>19.680675</td>\n      <td>110.990387</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>127.219879</td>\n      <td>284.472297</td>\n      <td>158.646713</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"nasa.csv\")[['Est Dia in M(min)', 'Est Dia in M(max)', 'Miss Dist.(lunar)', 'Hazardous']].rename(columns={'Est Dia in M(min)': 'dia_min', 'Est Dia in M(max)': 'dia_max', 'Miss Dist.(lunar)': \"dist\"})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the distance metric\n",
    "\n",
    "We will define the distance between two asteroids in the dataset as the difference of their volume and the difference of their distance to earth. This is computed in `ellipsoid_distance`. A subfunction of this is `ellipsoid_volume` which computes the volume of an ellipsoid given its three axes. The formula for the volume of an ellipsoid is $V = \\frac{4}{3} \\pi a b c$ where $a$, $b$, and $c$ are the three axes of the ellipsoid. If the third axis is not provided, we will assume it to be the average of the first two axes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d7da1dda09d723e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def ellipsoid_volume(a: float, b: float, c=None):\n",
    "    if c is None:\n",
    "        c = (a + b) / 2\n",
    "    return 4/3 * np.pi * a * b * c\n",
    "\n",
    "\n",
    "def ellipsoid_distance(a, b):\n",
    "    return abs(ellipsoid_volume(*a[:2]) - ellipsoid_volume(*b[:2])) + abs(a[2] - b[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:04:34.440319700Z",
     "start_time": "2024-04-03T15:04:34.435145100Z"
    }
   },
   "id": "fce2eeb1d50ec6b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute the distance matrix\n",
    "\n",
    "Now, similar to the BACE notebook, we compute the pairwise distances for the samples and normalize them to be between 0 and 1. We will use this distance matrix as the input to DataSAIL."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee00bdcf70252068"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c18c0a-7bfd-4ee5-a9f2-699a9b22a1e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T15:05:20.569412600Z",
     "start_time": "2024-04-03T15:04:34.450119900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00000000e+00, 2.79635710e-07, 2.73645278e-06, 5.44323262e-07],\n       [2.79635710e-07, 0.00000000e+00, 2.45681707e-06, 8.23958476e-07],\n       [2.73645278e-06, 2.45681707e-06, 0.00000000e+00, 3.28077422e-06],\n       [5.44323262e-07, 8.23958476e-07, 3.28077422e-06, 0.00000000e+00]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.values\n",
    "dist = np.zeros((df.shape[0], df.shape[0]))\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        dist[i, j] = ellipsoid_distance(data[i, :-1], data[j, :-1])\n",
    "        dist[j, i] = dist[i, j]\n",
    "dist /= np.max(dist)\n",
    "dist[:4, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split the dataset\n",
    "\n",
    "We will now split the dataset using DataSAIL. We will use the `I1e` technique to split the dataset by the diameters and the `C1e` technique to split the dataset by the distance to earth. \n",
    "\n",
    "Given there exist files storing the data and distance as described in the documentation, the according call to DataSAIL in the commandline would be:\n",
    "```bash\n",
    "$ datasail -t I1e C1e -s 8 1 -n train test -r 1 --solver SCIP --e-type O --e-data <filepath> --e-dist <filepath>\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12effa4cb39f9288"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Apr 03 04:18:30 PM: Your problem has 538 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Apr 03 04:18:30 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Apr 03 04:18:30 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Apr 03 04:18:30 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Apr 03 04:18:30 PM: Compiling problem (target solver=SCIP).\n",
      "(CVXPY) Apr 03 04:18:30 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCIP\n",
      "(CVXPY) Apr 03 04:18:30 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Apr 03 04:18:30 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Apr 03 04:18:30 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Apr 03 04:18:30 PM: Applying reduction SCIP\n",
      "(CVXPY) Apr 03 04:18:30 PM: Finished problem compilation (took 1.264e-01 seconds).\n",
      "(CVXPY) Apr 03 04:18:30 PM: Invoking solver SCIP  to obtain a solution.\n",
      "(CVXPY) Apr 03 04:18:30 PM: Problem status: optimal\n",
      "(CVXPY) Apr 03 04:18:30 PM: Optimal value: 1.000e+00\n",
      "(CVXPY) Apr 03 04:18:30 PM: Compilation took 1.264e-01 seconds\n",
      "(CVXPY) Apr 03 04:18:30 PM: Solver (including time spent in interface) took 2.751e-01 seconds\n",
      "(CVXPY) Apr 03 04:18:31 PM: Your problem has 1325 variables, 1228 constraints, and 0 parameters.\n",
      "(CVXPY) Apr 03 04:18:32 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Apr 03 04:18:32 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Apr 03 04:18:32 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Apr 03 04:18:33 PM: Compiling problem (target solver=SCIP).\n",
      "(CVXPY) Apr 03 04:18:33 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCIP\n",
      "(CVXPY) Apr 03 04:18:33 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Apr 03 04:18:33 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Apr 03 04:18:33 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Apr 03 04:18:35 PM: Applying reduction SCIP\n",
      "(CVXPY) Apr 03 04:18:36 PM: Finished problem compilation (took 3.702e+00 seconds).\n",
      "(CVXPY) Apr 03 04:18:36 PM: Invoking solver SCIP  to obtain a solution.\n",
      "(CVXPY) Apr 03 04:18:37 PM: Problem status: optimal\n",
      "(CVXPY) Apr 03 04:18:37 PM: Optimal value: -5.266e+01\n",
      "(CVXPY) Apr 03 04:18:37 PM: Compilation took 3.702e+00 seconds\n",
      "(CVXPY) Apr 03 04:18:37 PM: Solver (including time spent in interface) took 4.942e-01 seconds\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "e_splits, f_splits, inter_splits = datasail(\n",
    "    techniques=[\"I1e\", \"C1e\"],\n",
    "    splits=[8, 2],\n",
    "    names=[\"train\", \"test\"],\n",
    "    runs=1,\n",
    "    epsilon=0.1,\n",
    "    solver=\"SCIP\",\n",
    "    e_type=\"O\",\n",
    "    e_data={i: (row['dia_min'], row['dia_max']) for i, (_, row) in enumerate(df.iterrows())},\n",
    "    e_dist=(list(range(len(df))), dist),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:05:28.098732300Z",
     "start_time": "2024-04-03T15:05:20.558646100Z"
    }
   },
   "id": "0daabed1-540b-48bf-8e3d-0f746ecb4315"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Investigate the splits\n",
    "\n",
    "Finally, we inspect the e_split object as this holds all the assignments of the datapoints to the splits, for each run and each technique. First, the overall architecture is described, lastly we look at the first five assignments of the C1 run 0."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c2aa4792943f649"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "755b942c-d2ef-4829-8dbd-b97e84126b9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T15:05:28.527090200Z",
     "start_time": "2024-04-03T15:05:28.044979600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "I1e - Type: <class 'list'> - Length: 1\n",
      "\tRun 1 - Type: <class 'dict'> - 4687 assignments\n",
      "C1e - Type: <class 'list'> - Length: 1\n",
      "\tRun 1 - Type: <class 'dict'> - 4687 assignments\n",
      "\n",
      "ID: 0 - Split: train\n",
      "ID: 4 - Split: train\n",
      "ID: 59 - Split: train\n",
      "ID: 151 - Split: train\n",
      "ID: 393 - Split: train\n"
     ]
    }
   ],
   "source": [
    "print(type(e_splits))\n",
    "for key in e_splits.keys():\n",
    "    print(f\"{key} - Type: {type(e_splits[key])} - Length: {len(e_splits[key])}\")\n",
    "    for run in range(len(e_splits[key])):\n",
    "        print(f\"\\tRun {run + 1} - Type: {type(e_splits[key][run])} - {len(e_splits[key][run])} assignments\")\n",
    "print(\"\\n\" + \"\\n\".join(f\"ID: {idx} - Split: {split}\" for idx, split in list(e_splits[key][0].items())[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and test a Random Forest classifier\n",
    "\n",
    "Finally, we train and test a Random Forest classifier on the two splits. We will first extract the indices of the training and testing samples for the two splits and then train and test the classifier on the two splits."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c23791ffa8c6d69"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "rand_train = [i for i in range(len(df)) if e_splits['I1e'][0][i] == \"train\"]\n",
    "rand_test = [i for i in range(len(df)) if e_splits['I1e'][0][i] == \"test\"]\n",
    "sail_train = [i for i in range(len(df)) if e_splits['C1e'][0][i] == \"train\"]\n",
    "sail_test = [i for i in range(len(df)) if e_splits['C1e'][0][i] == \"test\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:05:28.557903400Z",
     "start_time": "2024-04-03T15:05:28.184097300Z"
    }
   },
   "id": "1526293448515c2a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7608530083777608"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rand_train = df.iloc[rand_train].drop(columns='Hazardous')\n",
    "y_rand_train = df.iloc[rand_train]['Hazardous']\n",
    "X_rand_test = df.iloc[rand_test].drop(columns='Hazardous')\n",
    "y_rand_test = df.iloc[rand_test]['Hazardous']\n",
    "\n",
    "rand_clf = RandomForestClassifier()\n",
    "rand_clf.fit(X_rand_train, y_rand_train)\n",
    "rand_score = rand_clf.score(X_rand_test, y_rand_test)\n",
    "rand_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:05:29.075128800Z",
     "start_time": "2024-04-03T15:05:28.459282200Z"
    }
   },
   "id": "288c18f7473dcfa7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, we reach an accuracy of 0.76 on a random split. Let's see how well we can do on the DataSAIL split."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd050d4f71142c6a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6046242774566474"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sail_train = df.iloc[sail_train].drop(columns='Hazardous')\n",
    "y_sail_train = df.iloc[sail_train]['Hazardous']\n",
    "X_sail_test = df.iloc[sail_test].drop(columns='Hazardous')\n",
    "y_sail_test = df.iloc[sail_test]['Hazardous']\n",
    "\n",
    "sail_clf = RandomForestClassifier()\n",
    "sail_clf.fit(X_sail_train, y_sail_train)\n",
    "sail_score = sail_clf.score(X_sail_test, y_sail_test)\n",
    "sail_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:05:29.696917100Z",
     "start_time": "2024-04-03T15:05:29.073200900Z"
    }
   },
   "id": "9959fc65581b4e39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
